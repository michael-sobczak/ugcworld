{
	"version": "1.0",
	"description": "Local LLM Model Registry - Managed by manage_models.py",
	"models": [
		{
			"id": "phi-3.5-instruct",
			"display_name": "Phi-3.5 Mini Instruct (Q4_K_M)",
			"backend": "llama.cpp",
			"context_length": 131072,
			"recommended_threads": 4,
			"quantization": "Q4_K_M",
			"file_path_in_pck": "res://models/phi-3.5-mini-instruct-q4_k_m.gguf",
			"sha256": "",
			"size_bytes": 2393232672,
			"estimated_memory": 2868000000,
			"description": "Lightweight chat - Fast responses, lower memory usage",
			"tags": [
				"lightweight",
				"3.8b",
				"quantized",
				"fast"
			],
			"prompt_template": {
				"system_prefix": "<|system|>\n",
				"system_suffix": "<|end|>\n",
				"user_prefix": "<|user|>\n",
				"user_suffix": "<|end|>\n",
				"assistant_prefix": "<|assistant|>\n",
				"assistant_suffix": "<|end|>\n"
			}
		},
		{
			"id": "qwen2.5-coder-14b",
			"display_name": "Qwen 2.5 Coder 14B (Q4_K_M)",
			"backend": "llama.cpp",
			"context_length": 32768,
			"recommended_threads": 8,
			"quantization": "Q4_K_M",
			"file_path_in_pck": "res://models/qwen2.5-coder-14b-instruct-q4_k_m.gguf",
			"sha256": "",
			"size_bytes": 8988110272,
			"estimated_memory": 10432457932,
			"description": "Agent planner - Code generation and planning for spell systems",
			"tags": [
				"coding",
				"14b",
				"quantized",
				"default"
			],
			"prompt_template": {
				"system_prefix": "<|im_start|>system\n",
				"system_suffix": "<|im_end|>\n",
				"user_prefix": "<|im_start|>user\n",
				"user_suffix": "<|im_end|>\n",
				"assistant_prefix": "<|im_start|>assistant\n",
				"assistant_suffix": "<|im_end|>\n"
			}
		},
		{
			"id": "deepseek-coder-v2",
			"display_name": "DeepSeek Coder V2 Lite (Q4_K_M)",
			"backend": "llama.cpp",
			"context_length": 163840,
			"recommended_threads": 8,
			"quantization": "Q4_K_M",
			"file_path_in_pck": "res://models/deepseek-coder-v2-lite-instruct-q4_k_m.gguf",
			"sha256": "",
			"size_bytes": 10364416768,
			"estimated_memory": 10728000000,
			"description": "Deterministic executor - Precise code execution and validation",
			"tags": [
				"coding",
				"executor",
				"16b",
				"quantized"
			],
			"prompt_template": {
				"system_prefix": "",
				"system_suffix": "\n\n",
				"user_prefix": "### Instruction:\n",
				"user_suffix": "\n\n",
				"assistant_prefix": "### Response:\n",
				"assistant_suffix": "\n\n"
			}
		},
		{
			"id": "deepseek-r1-distill-14b",
			"display_name": "DeepSeek R1 Distill Qwen 14B (Q4_K_M)",
			"backend": "llama.cpp",
			"context_length": 131072,
			"recommended_threads": 8,
			"quantization": "Q4_K_M",
			"file_path_in_pck": "res://models/deepseek-r1-distill-qwen-14b-q4_k_m.gguf",
			"sha256": "",
			"size_bytes": 8988110240,
			"estimated_memory": 11580653568,
			"description": "Reasoning model - Chain-of-thought reasoning distilled from DeepSeek R1, strong at code and math",
			"tags": [
				"reasoning",
				"coding",
				"14b",
				"quantized",
				"r1"
			],
			"prompt_template": {
				"system_prefix": "<|begin\u2581of\u2581sentence|>",
				"system_suffix": "\n",
				"user_prefix": "<|User|>",
				"user_suffix": "\n",
				"assistant_prefix": "<|Assistant|>",
				"assistant_suffix": "\n"
			}
		},
		{
			"id": "qwen3-32b",
			"display_name": "Qwen3 32B (Q4_K_M)",
			"backend": "llama.cpp",
			"context_length": 131072,
			"recommended_threads": 8,
			"quantization": "Q4_K_M",
			"file_path_in_pck": "res://models/qwen3-32b-q4_k_m.gguf",
			"sha256": "",
			"size_bytes": 19762149696,
			"estimated_memory": 25466653900,
			"description": "Flagship model - Latest Qwen3 32B with thinking mode, strongest overall quality",
			"tags": [
				"reasoning",
				"coding",
				"32b",
				"quantized",
				"flagship"
			],
			"prompt_template": {
				"system_prefix": "<|im_start|>system\n",
				"system_suffix": "<|im_end|>\n",
				"user_prefix": "<|im_start|>user\n",
				"user_suffix": "<|im_end|>\n",
				"assistant_prefix": "<|im_start|>assistant\n",
				"assistant_suffix": "<|im_end|>\n"
			}
		}
	],
	"presets": {
		"coding": {
			"temperature": 0.0,
			"top_p": 0.9,
			"top_k": 40,
			"repeat_penalty": 1.1,
			"max_tokens": 1024,
			"system_prompt": "You are a helpful coding assistant. Provide clear, concise, and correct code solutions."
		},
		"creative": {
			"temperature": 0.0,
			"top_p": 0.95,
			"top_k": 50,
			"repeat_penalty": 1.05,
			"max_tokens": 512,
			"system_prompt": "You are a creative writing assistant."
		},
		"precise": {
			"temperature": 0.0,
			"top_p": 0.8,
			"top_k": 20,
			"repeat_penalty": 1.2,
			"max_tokens": 256,
			"system_prompt": "You are a precise technical assistant. Be accurate and concise."
		},
		"conversational": {
			"temperature": 0.0,
			"top_p": 0.9,
			"top_k": 40,
			"repeat_penalty": 1.1,
			"max_tokens": 512,
			"system_prompt": "You are a friendly and helpful assistant."
		}
	}
}